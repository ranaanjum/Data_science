{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values Imputation Funcation Using ML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps:\n",
    "1. Import Libraries\n",
    "2. Load The Dataset\n",
    "3. Find The Column With Missing Values And Store In An Object\n",
    "4. Find The Column Based On Data Type\n",
    "   1. Numeric\n",
    "   2. Categorical\n",
    "   3. Boolean\n",
    "5. Define The Function To Impute The Missing Values\n",
    "6. Apply The Function To Our Dataset With Missing Values\n",
    "7. Check The Missing Values After Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score,precision_score,mean_absolute_error,r2_score\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
       "3          normal   187.0  False      3.5  downsloping  0.0   \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
       "\n",
       "                thal  num  \n",
       "0       fixed defect    0  \n",
       "1             normal    2  \n",
       "2  reversable defect    1  \n",
       "3             normal    0  \n",
       "4             normal    0  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Load the dataset\n",
    "df = pd.read_csv('./heart_disease_uci.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ca          611\n",
       "thal        486\n",
       "slope       309\n",
       "fbs          90\n",
       "oldpeak      62\n",
       "trestbps     59\n",
       "thalch       55\n",
       "exang        55\n",
       "chol         30\n",
       "restecg       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Find the columns with missing values and store it an object\n",
    "missing_data_cols = df.isnull().sum()[df.isnull().sum() > 0].sort_values(ascending = False)\n",
    "missing_data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'age', 'sex', 'dataset', 'cp', 'trestbps', 'chol', 'fbs',\n",
       "       'restecg', 'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns: ['sex', 'dataset', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
      "Numeric Columns: ['id', 'age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca', 'num']\n"
     ]
    }
   ],
   "source": [
    "# 4. Find the only categorical columns\n",
    "cat_cols = df.select_dtypes(include = \"object\").columns.tolist()\n",
    "\n",
    "# Find the only numeric columns\n",
    "num_cols = df.select_dtypes(include = ['float64','int64'] ).columns.tolist()\n",
    "\n",
    "# print the categorical and numeric columns\n",
    "print('Categorical Columns:', cat_cols)\n",
    "print('Numeric Columns:', num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. define function to impute missing values in categorical or object columns\n",
    "\n",
    "def impute_cat_cols(df, passed_col):\n",
    "    # Ensure passed_col is categorical\n",
    "    df[passed_col] = df[passed_col].astype('category')\n",
    "\n",
    "    # Split df into null and not-null based on passed_col\n",
    "    df_null = df[df[passed_col].isnull()]\n",
    "    df_not_null = df[df[passed_col].notnull()]\n",
    "\n",
    "    # Prepare X for model fitting\n",
    "    X = df_not_null.drop(columns=[passed_col])\n",
    "\n",
    "    # Create a mapping for all unique categories including unseen ones\n",
    "    unique_categories = pd.concat([df[passed_col], pd.Series([2])]).unique()\n",
    "    category_mapping = {k: v for v, k in enumerate(unique_categories)}\n",
    "\n",
    "    # Transform y using the manual mapping\n",
    "    y_transformed = df_not_null[passed_col].map(category_mapping)\n",
    "\n",
    "    # Encode categorical features in X\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype.name == 'category' or X[col].dtype.name == 'object':\n",
    "            X[col] = label_encoder.fit_transform(X[col].astype(str))\n",
    "\n",
    "    # Fit the model\n",
    "    rf_classifier = RandomForestClassifier(random_state=42)\n",
    "    rf_classifier.fit(X, y_transformed)\n",
    "\n",
    "    # Predict on the null set\n",
    "    X_null = df_null.drop(columns=[passed_col])\n",
    "    \n",
    "    # Ensure X_null undergoes the same encoding transformations as X\n",
    "    for col in X_null.columns:\n",
    "        if X_null[col].dtype.name == 'category' or X_null[col].dtype.name == 'object':\n",
    "            if col in label_encoder.classes_:\n",
    "                X_null[col] = label_encoder.transform(X_null[col].astype(str))\n",
    "            else:\n",
    "                X_null[col] = label_encoder.fit_transform(X_null[col].astype(str))\n",
    "\n",
    "    # Check if there are any missing values left in X_null that need to be imputed before prediction\n",
    "    if X_null.isnull().any().any():\n",
    "        # Handle remaining missing values here before prediction\n",
    "        pass\n",
    "\n",
    "    # Predict and update original DataFrame\n",
    "    predicted_values = rf_classifier.predict(X_null)\n",
    "    \n",
    "    # Inverse map the predicted codes to original categories using the manual mapping\n",
    "    inverse_category_mapping = {v: k for k, v in category_mapping.items()}\n",
    "    predicted_categories = [inverse_category_mapping[code] for code in predicted_values]\n",
    "    \n",
    "    # Get unique new categories to add\n",
    "    new_categories = set(predicted_categories) - set(df[passed_col].cat.categories)\n",
    "\n",
    "    # Update the categories of the original column before assigning new values\n",
    "    if new_categories:\n",
    "        df[passed_col] = df[passed_col].cat.add_categories(new_categories)\n",
    "    \n",
    "    # Assign the predicted categories to the null values in the DataFrame\n",
    "    df.loc[df[passed_col].isnull(), passed_col] = predicted_categories\n",
    "\n",
    "# # Example usage:\n",
    "# impute_cat_cols(df, 'restecg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            0\n",
      "age           0\n",
      "sex           0\n",
      "dataset       0\n",
      "cp            0\n",
      "trestbps     59\n",
      "chol         30\n",
      "fbs           0\n",
      "restecg       0\n",
      "thalch       55\n",
      "exang         0\n",
      "oldpeak      62\n",
      "slope         0\n",
      "ca          611\n",
      "thal          0\n",
      "num           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Call the function with 'thal' as an example column name and pass the DataFrame as an argument\n",
    "impute_cat_cols(df, 'fbs')\n",
    "impute_cat_cols(df, 'restecg')\n",
    "impute_cat_cols(df, 'exang')\n",
    "impute_cat_cols(df, 'slope')\n",
    "impute_cat_cols(df, 'thal')\n",
    "\n",
    "\n",
    "# Now check for missing values in 'thal' column\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. define function to impute missing values in numerical columns\n",
    "\n",
    "def impute_num_cols(df, passed_col):\n",
    "    # Step 1: Split the DataFrame into two parts based on null values in the passed_col\n",
    "    df_null = df[df[passed_col].isnull()]\n",
    "    df_not_null = df[df[passed_col].notnull()]\n",
    "\n",
    "    # Step 2: Prepare the feature set (X) by dropping the passed_col from the non-null DataFrame\n",
    "    X = df_not_null.drop(columns=[passed_col])\n",
    "\n",
    "    # Step 3: Prepare the target set (y) which is the non-null values of passed_col\n",
    "    y = df_not_null[passed_col]\n",
    "\n",
    "    # Step 4: Encode all categorical features in X using LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype.name == 'category' or X[col].dtype.name == 'object':\n",
    "            X[col] = label_encoder.fit_transform(X[col].astype(str))\n",
    "\n",
    "    # Step 5: Fit a RandomForestRegressor on the encoded features and target\n",
    "    rf_regressor = RandomForestRegressor(random_state=42)\n",
    "    rf_regressor.fit(X, y)\n",
    "\n",
    "    # Step 6: Predict missing values in passed_col using the trained model on the null DataFrame\n",
    "    X_null = df_null.drop(columns=[passed_col])\n",
    "    \n",
    "    # Ensure that X_null undergoes the same encoding transformations as X\n",
    "    for col in X_null.columns:\n",
    "        if X_null[col].dtype.name == 'category' or X_null[col].dtype.name == 'object':\n",
    "            if col in label_encoder.classes_:\n",
    "                X_null[col] = label_encoder.transform(X_null[col].astype(str))\n",
    "            else:\n",
    "                X_null[col] = label_encoder.fit_transform(X_null[col].astype(str))\n",
    "\n",
    "    # Check if there are any missing values left in X_null that need to be imputed before prediction\n",
    "    if X_null.isnull().any().any():\n",
    "        # Handle remaining missing values here before prediction\n",
    "        pass\n",
    "\n",
    "    # Step 7: Predict and update original DataFrame with predicted values for null values\n",
    "    predicted_values = rf_regressor.predict(X_null)\n",
    "    \n",
    "    df.loc[df[passed_col].isnull(), passed_col] = predicted_values\n",
    "\n",
    "# Example usage:\n",
    "# impute_num_cols(df, 'age')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
       "3          normal   187.0  False      3.5  downsloping  0.0   \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
       "\n",
       "                thal  num  \n",
       "0       fixed defect    0  \n",
       "1             normal    2  \n",
       "2  reversable defect    1  \n",
       "3             normal    0  \n",
       "4             normal    0  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "age         0\n",
      "sex         0\n",
      "dataset     0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalch      0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "num         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "impute_num_cols(df, 'trestbps')\n",
    "impute_num_cols(df, 'chol')\n",
    "impute_num_cols(df, 'thalch')\n",
    "impute_num_cols(df, 'oldpeak')\n",
    "impute_num_cols(df, 'ca')\n",
    "\n",
    "\n",
    "# Now check for missing values in 'thal' column\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Sir Ammar Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to impute the missing values in thal column\n",
    "\n",
    "def impute_categorical_missing_data(passed_col):\n",
    "    \n",
    "    df_null = df[df[passed_col].isnull()]\n",
    "    df_not_null = df[df[passed_col].notnull()]\n",
    "\n",
    "    X = df_not_null.drop(passed_col, axis=1)\n",
    "    y = df_not_null[passed_col]\n",
    "    \n",
    "    other_missing_cols = [col for col in missing_data_cols if col != passed_col]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
    "            X[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "    if passed_col in bool_cols:\n",
    "        y = label_encoder.fit_transform(y)\n",
    "        \n",
    "    iterative_imputer = IterativeImputer(estimator=RandomForestRegressor(random_state=42), add_indicator=True)\n",
    "\n",
    "    for col in other_missing_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            col_with_missing_values = X[col].values.reshape(-1, 1)\n",
    "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
    "            X[col] = imputed_values[:, 0]\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"The feature '\"+ passed_col+ \"' has been imputed with\", round((acc_score * 100), 2), \"accuracy\\n\")\n",
    "\n",
    "    X = df_null.drop(passed_col, axis=1)\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
    "            X[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "    for col in other_missing_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            col_with_missing_values = X[col].values.reshape(-1, 1)\n",
    "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
    "            X[col] = imputed_values[:, 0]\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "    if len(df_null) > 0: \n",
    "        df_null[passed_col] = rf_classifier.predict(X)\n",
    "        if passed_col in bool_cols:\n",
    "            df_null[passed_col] = df_null[passed_col].map({0: False, 1: True})\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    df_combined = pd.concat([df_not_null, df_null])\n",
    "    \n",
    "    return df_combined[passed_col]\n",
    "\n",
    "def impute_continuous_missing_data(passed_col):\n",
    "    \n",
    "    df_null = df[df[passed_col].isnull()]\n",
    "    df_not_null = df[df[passed_col].notnull()]\n",
    "\n",
    "    X = df_not_null.drop(passed_col, axis=1)\n",
    "    y = df_not_null[passed_col]\n",
    "    \n",
    "    other_missing_cols = [col for col in missing_data_cols if col != passed_col]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
    "            X[col] = label_encoder.fit_transform(X[col])\n",
    "    \n",
    "    iterative_imputer = IterativeImputer(estimator=RandomForestRegressor(random_state=42), add_indicator=True)\n",
    "\n",
    "    for col in other_missing_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            col_with_missing_values = X[col].values.reshape(-1, 1)\n",
    "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
    "            X[col] = imputed_values[:, 0]\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    rf_regressor = RandomForestRegressor()\n",
    "\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "    print(\"MAE =\", mean_absolute_error(y_test, y_pred), \"\\n\")\n",
    "    print(\"RMSE =\", mean_squared_error(y_test, y_pred, squared=False), \"\\n\")\n",
    "    print(\"R2 =\", r2_score(y_test, y_pred), \"\\n\")\n",
    "\n",
    "    X = df_null.drop(passed_col, axis=1)\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
    "            X[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "    for col in other_missing_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            col_with_missing_values = X[col].values.reshape(-1, 1)\n",
    "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
    "            X[col] = imputed_values[:, 0]\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "    if len(df_null) > 0: \n",
    "        df_null[passed_col] = rf_regressor.predict(X)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    df_combined = pd.concat([df_not_null, df_null])\n",
    "    \n",
    "    return df_combined[passed_col]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
